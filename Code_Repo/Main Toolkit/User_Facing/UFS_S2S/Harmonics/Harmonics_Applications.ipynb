{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0f8a727-7970-4676-829c-14127f8cdb6e",
   "metadata": {},
   "source": [
    "<a name=\"top\"></a>\n",
    "<div style=\"width:1000 px\">\n",
    "\n",
    "<div style=\"float:right; width:98 px; height:98px;\">\n",
    "<img src=\"https://cdn.miami.edu/_assets-common/images/system/um-logo-gray-bg.png\" alt=\"Miami Logo\" style=\"height: 98px;\">\n",
    "</div>\n",
    "\n",
    "<div style=\"float:right; width:98 px; height:98px;\">\n",
    "<img src=\"https://media.licdn.com/dms/image/C4E0BAQFlOZSAJABP4w/company-logo_200_200/0/1548285168598?e=2147483647&v=beta&t=g4jl8rEhB7HLJuNZhU6OkJWHW4cul_y9Kj_aoD7p0_Y\" alt=\"STI Logo\" style=\"height: 98px;\">\n",
    "</div>\n",
    "\n",
    "\n",
    "<h1>Compute Harmonics on the sFWRD Database</h1>\n",
    "By: Tyler M. Fenske\n",
    "    <br>\n",
    "Last Edited: 2024-02-01\n",
    "<br>\n",
    "<br>    \n",
    "<br>\n",
    "This notebook applies harmonics analysis to various forecast and renalysis data as part of the data pre-processing for future forecasting work. \n",
    "<br>    \n",
    "<br>\n",
    "Note: some of the datasets were too large to be processed all at once. The work around is to use Split_BigData.ipynb that takes a given model and splits each yearly variable file into 4 distinct quadrant files spatially and rejoining them after harmonic processing. \n",
    "<br>    \n",
    "<br>\n",
    "<div style=\"clear:both\"></div>\n",
    "</div>\n",
    "\n",
    "<hr style=\"height:2px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50716cc3-a474-40bf-90ac-47de0cc43515",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Imports & Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1478728-4925-423a-b5f1-38b5f91fa7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6509aaa9-3d87-4574-9e78-6ad206134e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run File_concat_mod_functions.ipynb\n",
    "#include many of the existing functions to handle the NOAA S2S database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd3398de-4ea8-4f1d-a0a2-0caccd410b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_concat(model_list, model):\n",
    "\n",
    "    '''\n",
    "    Takes a list of files and concatenates them along the time dimension.\n",
    "\n",
    "    Inputs:\n",
    "    \n",
    "    model_list: (list of str) list of filenames to be opened and concatenates them along the time dimension \n",
    "    model: (str) one of the six available model outputs in the database (does not work for UFS)\n",
    "    \n",
    "    Outputs:\n",
    "\n",
    "    df1: (xarray dataset) combined dataset of all files along the time dimension\n",
    "\n",
    "    '''\n",
    "\n",
    "    \n",
    "\n",
    "    if model == 'CONUS404':\n",
    "        cc_dim = 'Time'\n",
    "        df1 = xr.open_dataset(model_list[0]).astype('float32') #.chunk(get_chunk_database(model))\n",
    "    \n",
    "        for f in model_list[1:]:\n",
    "            df2 = xr.open_dataset(f).astype('float32') #.chunk(get_chunk_database(model))\n",
    "            df1 = xr.concat([df1, df2], dim = cc_dim)\n",
    "    else:\n",
    "        cc_dim = 'time'\n",
    "    \n",
    "        df1 = xr.open_dataset(model_list[0]).astype('float32') #.chunk(get_chunk_database(model))\n",
    "    \n",
    "        for f in model_list[1:]:\n",
    "            df2 = xr.open_dataset(f).astype('float32')#.chunk(get_chunk_database(model))\n",
    "            print(f)\n",
    "            df1 = xr.concat([df1, df2], dim = cc_dim)\n",
    "    \n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4ac7c2b-c72a-4af7-9d23-b5fce06539a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_database_abs_file_xr(model, var, year):\n",
    "    \n",
    "    '''This function opens and returns an xarray dataset for a given:\n",
    "       model : one of the six available model outputs in the database (does not work for UFS)\n",
    "       var   : any var present in the database (must match an available var or will throw an error)\n",
    "       year  : same as var, but for year instead'''\n",
    "\n",
    "    path = f'/raid60B/s2sfire/NOAA_S2S/database_files_final/{model}/'\n",
    "    base = get_filename(model)\n",
    "    name = f'{path}{var}_{base}_Abs_{str(year)}.nc'\n",
    "\n",
    "    df = xr.open_dataset(name, decode_times=True)[var]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a54a7233-bbd5-43df-b1e5-5caa28554da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = {\n",
    "    'time': {\n",
    "        'units': 'hours since 2000-01-01 0Z',\n",
    "        'calendar': 'standard'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7943b39-56ce-4763-9ad8-1f79c937fc7e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Harmonics Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bd95a9-a6d7-41f7-a2e1-33923c223876",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def compute_harmonics(yt, k=10, offbyone=False):\n",
    "    \n",
    "    '''This function is based off of Section 8.4 (Frequency Domain - 1. Harmonic Analysis)\n",
    "        from the textbook Statistical Methods in the Atmospheric Sciences by Wilks (2006).\n",
    "        This function calculates a specified number of harmonics, or fitted cosine curves,\n",
    "        for a given time series. It functions very similiarly to fourier analysis.\n",
    "        \n",
    "        Inputs: \n",
    "        yt : a 1-d time series to perform harmonics analysis on\n",
    "        k  : the number of harmonics to compute\n",
    "        \n",
    "        Outputs: \n",
    "        yt0  : the sum of the k-harmonics computed\n",
    "        ybar : the mean of yt\n",
    "        C    : the coefficient for each harmonic\n",
    "        w    : the frequency adjustment for each harmonic\n",
    "        \n",
    "        KEYWORDS\n",
    "        offbyone : use if your iterator should start at 1 (Python iterators start at 0)\n",
    "                   (do not use if unsure; for long time series (100+), it won't matter)'''\n",
    "\n",
    "    n = yt.shape[-1]                                                                                                          # Make time the last dimension \n",
    "                       \n",
    "    if (k > int(n/2)):                                                                                                        # Ensure the number of harmonics is within the valid range\n",
    "        k = int(n/2)                                                                                                          # Set k to the maximum valid number of harmonics\n",
    "                       \n",
    "    x    = np.linspace(1, n, n) - 1                                                                                           # Create an array of time indices\n",
    "    ybar = np.nanmean(yt, axis=-1, keepdims=True)                                                                             # Compute the mean of yt along the time dimension\n",
    "    freq = 2 * np.pi * x / n                                                                                                  # Compute the frequency array\n",
    "                   \n",
    "    harmonics_range = np.arange(1, k + 1)                                                                                     # Create an array of harmonic indices\n",
    "                   \n",
    "    cos_terms = np.cos(freq * harmonics_range[:, np.newaxis])[np.newaxis, np.newaxis, ...]                                    # Compute cosine terms for harmonics\n",
    "    sin_terms = np.sin(freq * harmonics_range[:, np.newaxis])[np.newaxis, np.newaxis, ...]                                    # Compute sine terms for harmonics\n",
    "                       \n",
    "    A = (2 / n) * np.nansum(yt[:, :, np.newaxis, :] * cos_terms, axis=-1)                                                     # Compute cosine coefficients\n",
    "    B = (2 / n) * np.nansum(yt[:, :, np.newaxis, :] * sin_terms, axis=-1)                                                     # Compute sine coefficients\n",
    "                   \n",
    "    C = np.sqrt(A**2 + B**2)                                                                                                  # Compute the amplitude of the harmonics\n",
    "                   \n",
    "    w = np.where(A == 0, np.pi / 2, np.arctan(B / A))                                                                         # Compute the phase angle\n",
    "    w = np.where(A < 0, w + np.pi, w)                                                                                         # Adjust phase angle for negative cosine coefficients\n",
    "    w = np.where(w >= 2 * np.pi, w - 2 * np.pi, w)                                                                            # Ensure phase angle is within the range [0, 2Ï€]\n",
    "                   \n",
    "    if (offbyone):                                                                                                            # Check for off-by-one error\n",
    "        w += np.deg2rad(1 / n)                                                                                                # Adjust phase angle to correct off-by-one error\n",
    "                   \n",
    "    yt0 = np.repeat(ybar, n, axis=-1)                                                                                         # Initialize the reconstructed time series with the mean\n",
    "                   \n",
    "    freq_adjusted = freq[np.newaxis, np.newaxis, :, np.newaxis]                                                               # Adjust frequency array for broadcasting\n",
    "                   \n",
    "    harmonics_range = harmonics_range[np.newaxis, np.newaxis, np.newaxis, :]                                                  # Adjust harmonic range array for broadcasting\n",
    "                   \n",
    "    yt0 = yt0 + np.sum(C[:, :, np.newaxis, :] * np.cos(harmonics_range * freq_adjusted - w[:, :, np.newaxis, :]), axis=-1)    # Reconstruct the time series using harmonics\n",
    "\n",
    "    return (yt0, ybar.squeeze(axis=-1), C, w)                                                                                 # Return the reconstructed time series, mean, amplitude, and phase angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf643dbd-3a67-4efb-8e7a-df8ebf64f1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_harmonics_xr(data_xr, k=10, large_data=False):\n",
    "    '''This function is based off of Section 8.4 (Frequency Domain - 1. Harmonic Analysis)\n",
    "        from the textbook Statistical Methods in the Atmospheric Sciences by Wilks (2006).\n",
    "        This function calculates a specified number of harmonics, or fitted cosine curves,\n",
    "        for a given time series. It functions very similiarly to fourier analysis.\n",
    "        \n",
    "        Inputs: \n",
    "        data_xr : a 3-d (time, lat, lon) chunked dataarray to perform harmonics analysis on\n",
    "        k       : the number of harmonics to compute\n",
    "\n",
    "\n",
    "        Keywords:\n",
    "        large_data : Set to true if dealing with very large data (50+ GB); used for HRRR and CONUS404\n",
    "        \n",
    "        Outputs: \n",
    "        period_normal        : the sum of the k-harmonics computed\n",
    "        anomaly              : the raw input data minus the period normal data\n",
    "        harmonics_parameters : the coefficients and frequency adjustments for each harmonic'''\n",
    "\n",
    "    n = data_xr.time.shape[0]\n",
    "\n",
    "    if (k > int(n/2)):\n",
    "        k = int(n/2)\n",
    "\n",
    "    x    = np.linspace(1,n,n)-1\n",
    "    freq = 2*np.pi*x/n\n",
    "            \n",
    "    harmonics_range = np.arange(1,k+1)\n",
    "\n",
    "    base_terms = xr.DataArray(harmonics_range*freq[:,np.newaxis], \n",
    "                              dims=('time','harmonic'), \n",
    "                              coords={'time':data_xr.time.values,'harmonic':harmonics_range}).astype('float32')\n",
    "    cos_terms  = np.cos(base_terms)\n",
    "    sin_terms  = np.sin(base_terms)\n",
    "\n",
    "    if (large_data):\n",
    "        empty_array = np.zeros((k,data_xr.latitude.shape[0],data_xr.longitude.shape[0]))\n",
    "        A = xr.DataArray(empty_array, dims=('harmonic','latitude','longitude'),\n",
    "                         coords={'harmonic':harmonics_range,'latitude':data_xr.latitude,'longitude':data_xr.longitude}).astype('float32')\n",
    "        B = A.copy(deep=True)\n",
    "        print('Harmonics coefficients computed: ', end='')\n",
    "        for i in harmonics_range:\n",
    "            A[i-1,:,:] = (2/n)*(cos_terms.sel(harmonic=i)*data_xr).sum(dim='time')\n",
    "            B[i-1,:,:] = (2/n)*(sin_terms.sel(harmonic=i)*data_xr).sum(dim='time')\n",
    "            end = ',' if i < 10 else ''\n",
    "            print(i, end=end)\n",
    "        print(' Completed.')\n",
    "\n",
    "    else:\n",
    "        A = (2/n)*(cos_terms*data_xr).sum(dim='time')\n",
    "        B = (2/n)*(sin_terms*data_xr).sum(dim='time')\n",
    "    \n",
    "    C = (A**2 + B**2)**.5\n",
    "\n",
    "    w = np.where(A == 0, np.pi/2, np.arctan(B/A))\n",
    "    w = np.where(A < 0, w + np.pi, w)\n",
    "    w = np.where(w >= 2*np.pi, w - 2*np.pi, w)\n",
    "\n",
    "    C = xr.DataArray(C, dims=('harmonic','latitude','longitude'),\n",
    "                     coords={'harmonic':harmonics_range,'latitude':data_xr.latitude,'longitude':data_xr.longitude})\n",
    "    w = xr.DataArray(w, dims=('harmonic','latitude','longitude'),\n",
    "                     coords={'harmonic':harmonics_range,'latitude':data_xr.latitude,'longitude':data_xr.longitude})\n",
    "\n",
    "    if (large_data):\n",
    "        print('Harmonics added to mean to compute period normal: ', end='')\n",
    "        period_normal = data_xr.mean(dim='time') + ((C.sel(harmonic=1))*np.cos(base_terms.sel(harmonic=1) - w.sel(harmonic=1)))\n",
    "        print('1', end=',')\n",
    "        for i in harmonics_range[1:]:\n",
    "            period_normal = period_normal + ((C.sel(harmonic=i))*np.cos(base_terms.sel(harmonic=i) - w.sel(harmonic=i)))\n",
    "            end = ',' if i < 10 else ''\n",
    "            print(i, end=end)\n",
    "        print(' Completed.')      \n",
    "    else:\n",
    "        period_normal = data_xr.mean(dim='time') + (C*np.cos(base_terms - w)).sum(dim='harmonic')\n",
    "    \n",
    "    period_normal = period_normal.transpose('time','latitude','longitude').astype('float32')\n",
    "    period_normal = period_normal.assign_coords({'time': ('time', data_xr.time.values)})\n",
    "    period_normal.attrs = data_xr.attrs.copy()\n",
    "    for coord in data_xr.coords:\n",
    "        period_normal.coords[coord].attrs = data_xr.coords[coord].attrs.copy()\n",
    "\n",
    "    anomaly = data_xr - period_normal\n",
    "    anomaly = anomaly.transpose('time','latitude','longitude').astype('float32')\n",
    "    anomaly = anomaly.assign_coords({'time': ('time', data_xr.time.values)})\n",
    "    anomaly.attrs = data_xr.attrs.copy()\n",
    "    for coord in data_xr.coords:\n",
    "        anomaly.coords[coord].attrs = data_xr.coords[coord].attrs.copy()\n",
    "\n",
    "    period_normal        = period_normal.to_dataset(name=f'{data_xr.name}_periodnorm')\n",
    "    anomaly              = anomaly.to_dataset(name=f'{data_xr.name}_anom')\n",
    "    \n",
    "    harmonics_parameters = xr.Dataset({'Constants': C, \"Phis\": w})\n",
    "    \n",
    "    return period_normal, anomaly, harmonics_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f3d424-798f-485c-a05d-2fdece497dc4",
   "metadata": {},
   "source": [
    "## Application of the Harmonics Function\n",
    "\n",
    "Organized by model as each needs handled differently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c1b122-ded0-4f6f-bd5d-38d62bfb9478",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Initial Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f84ea9-c604-4362-96f7-34a2599c02bf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# raw_df = xr.open_mfdataset(f'{filepath}t2{filebase}*{suffix}', decode_times=True).chunk({'time': -1, 'latitude': 100, 'longitude': 100})\n",
    "\n",
    "# era5_period_normal, era5_anomaly, era5_harmonics_parameters = compute_harmonics_xr(raw_df['t2'])\n",
    "\n",
    "# era5_period_normal.attrs = raw_df.attrs.copy()\n",
    "# era5_anomaly.attrs       = raw_df.attrs.copy()\n",
    "\n",
    "# era5_period_normal.attrs.update({'File_creation_date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")})\n",
    "# era5_anomaly.attrs.update({'File_creation_date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")})\n",
    "\n",
    "# era5_period_normal['t2_periodnorm'].chunk({'time': 500, 'latitude': -1, 'longitude': -1})\n",
    "\n",
    "# for year, group in era5_period_normal.groupby('time.year'):\n",
    "#     filename = f'temp/era5_testdata_{year}.nc'\n",
    "#     group.to_netcdf(filename)\n",
    "\n",
    "# test  = xr.open_dataset('temp/era5_test.nc')\n",
    "# test1 = xr.open_dataset('temp/era5_testdata_2011.nc')\n",
    "# test2 = xr.open_dataset('temp/era5_testdata_2012.nc')\n",
    "\n",
    "# %%time\n",
    "# era5_period_normal.to_netcdf('temp/era5_test2.nc')\n",
    "# test2 = xr.open_dataset('temp/era5_test2.nc')\n",
    "# raw_df[:,0,0].plot(aspect=3, size=4)\n",
    "# test2['__xarray_dataarray_variable__'][:,0,0].plot()\n",
    "# (raw_df[:,0,0] - test2['__xarray_dataarray_variable__'][:,0,0]).plot(aspect=3, size=4)\n",
    "# era5_C.to_netcdf('temp/era5_harmonics_consts.nc')\n",
    "# era5_C = xr.open_dataset('temp/era5_harmonics_consts.nc')\n",
    "# old = xr.open_dataset('../harmonics_parameters/ERA5/t2m_Abs_ERA5_harmonics_parameters.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a68481-839e-47c9-a666-0d70eee9b008",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# var = vars[9]\n",
    "# datatype = 'Abs'\n",
    "# raw_df = xr.open_mfdataset(f'{filepath}{var}{filebase}{datatype}*.nc', decode_times=True, engine='netcdf4').load()\n",
    "# data_xr = raw_df[var]\n",
    "# k = 10\n",
    "\n",
    "# n = data_xr.time.shape[0]\n",
    "# if (k > int(n/2)):\n",
    "#     k = int(n/2)\n",
    "# x    = np.linspace(1,n,n)-1\n",
    "# freq = 2*np.pi*x/n\n",
    "        \n",
    "# harmonics_range = np.arange(1,k+1)\n",
    "# base_terms = xr.DataArray(harmonics_range*freq[:,np.newaxis], \n",
    "#                           dims=('time','harmonic')).astype('float32')\n",
    "# cos_terms  = np.cos(base_terms)\n",
    "# sin_terms  = np.sin(base_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b23b15-360d-4ab2-93a6-aca0fb37d803",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ERA5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96716541-42ec-4d1d-bd50-2b82cb4eb25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "\n",
    "model    = 'ERA5'\n",
    "filepath = '../database_files_final/ERA5/'\n",
    "filebase = '_ERA5_REANALYSIS_'\n",
    "\n",
    "vars = [\n",
    "    'cape', 'd2',  'ffwi',  'gust', 'hdw', \n",
    "    'lspr', 'pbl', 'prate', 'rh',   't2',\n",
    "    'tcp',  'tp',  'u10',   'v10',  'vpd',\n",
    "    'vsm',  'wd',  'ws']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f364bd-d855-4fec-938e-03b9a02b268c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for var in vars:\n",
    "    for datatype in ['Abs', 'MIN', 'MAX', 'AVG']:\n",
    "        raw_df = xr.open_mfdataset(f'{filepath}{var}{filebase}{datatype}*.nc', decode_times=True, engine='netcdf4').load()\n",
    "      \n",
    "        print(f'Data loaded, applying harmonics to: {var} {datatype}... ')\n",
    "                \n",
    "        period_normal, anomaly, harmonics_parameters = compute_harmonics_xr(raw_df[var], k=k)\n",
    "\n",
    "        period_normal.attrs = raw_df.attrs.copy()\n",
    "        anomaly.attrs       = raw_df.attrs.copy()\n",
    "\n",
    "        period_normal.attrs.update({'File_creation_date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")})\n",
    "        anomaly.attrs.update({'File_creation_date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")})\n",
    "\n",
    "        period_normal.to_netcdf(f'temp/{model}_{var}_{datatype}_periodnorm.nc', encoding=encoding)\n",
    "        anomaly.to_netcdf(f'temp/{model}_{var}_{datatype}_anomaly.nc', encoding=encoding)\n",
    "        harmonics_parameters.to_netcdf(f'../harmonics_parameters/{model}/{var}_{model}_{datatype}_harmonics_parameters.nc')\n",
    "\n",
    "        print('Full temp files written, splitting into yearly files... ')\n",
    "\n",
    "        period_normal = xr.open_dataset(f'temp/{model}_{var}_{datatype}_periodnorm.nc')#, chunks={'time': 100})\n",
    "        anomaly       = xr.open_dataset(f'temp/{model}_{var}_{datatype}_anomaly.nc')#, chunks={'time': 100})\n",
    "\n",
    "        for year, group in period_normal.groupby('time.year'):\n",
    "            filename = f'{filepath}Period_Normal/{var}{filebase}{datatype}_periodnorm_{year}.nc'\n",
    "            group.to_netcdf(filename, encoding=encoding)\n",
    "\n",
    "        for year, group in anomaly.groupby('time.year'):\n",
    "            filename = f'{filepath}Anomaly/{var}{filebase}{datatype}_anom_{year}.nc'\n",
    "            group.to_netcdf(filename, encoding=encoding)\n",
    "        \n",
    "        print(f'Complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca17818-a667-4cad-bf8f-86b6c3be11c0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### NCEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec409a2-b77a-437e-888a-82230816b0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "\n",
    "model    = 'NCEP'\n",
    "filepath = '../database_files_final/NCEP/'\n",
    "filebase = '_NCEP_REANALYSIS_V2_'\n",
    "\n",
    "vars = [\n",
    "    'ffwi', 'hdw', 'prate', 'rh',  'sm', \n",
    "    't2',   'u10', 'v10',   'vpd', 'vsm', \n",
    "    'wd',   'ws']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4917c49-3751-43fb-a73e-43225af36fc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for var in vars:\n",
    "    for datatype in ['Abs', 'MIN', 'MAX', 'AVG']:\n",
    "        raw_df = xr.open_mfdataset(f'{filepath}{var}{filebase}{datatype}*.nc', decode_times=True, engine='netcdf4').load()\n",
    "      \n",
    "        print(f'Data loaded, applying harmonics to: {var} {datatype}... ')\n",
    "                \n",
    "        period_normal, anomaly, harmonics_parameters = compute_harmonics_xr(raw_df[var], k=k)\n",
    "\n",
    "        period_normal.attrs = raw_df.attrs.copy()\n",
    "        anomaly.attrs       = raw_df.attrs.copy()\n",
    "\n",
    "        period_normal.attrs.update({'File_creation_date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")})\n",
    "        anomaly.attrs.update({'File_creation_date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")})\n",
    "\n",
    "        period_normal.to_netcdf(f'temp/{model}_{var}_{datatype}_periodnorm.nc', encoding=encoding)\n",
    "        anomaly.to_netcdf(f'temp/{model}_{var}_{datatype}_anomaly.nc', encoding=encoding)\n",
    "        harmonics_parameters.to_netcdf(f'../harmonics_parameters/{model}/{var}_{model}_{datatype}_harmonics_parameters.nc')\n",
    "\n",
    "        print('Full temp files written, splitting into yearly files... ')\n",
    "\n",
    "        period_normal = xr.open_dataset(f'temp/{model}_{var}_{datatype}_periodnorm.nc')#, chunks={'time': 100})\n",
    "        anomaly       = xr.open_dataset(f'temp/{model}_{var}_{datatype}_anomaly.nc')#, chunks={'time': 100})\n",
    "\n",
    "        for year, group in period_normal.groupby('time.year'):\n",
    "            filename = f'{filepath}Period_Normal/{var}{filebase}{datatype}_periodnorm_{year}.nc'\n",
    "            group.to_netcdf(filename, encoding=encoding)\n",
    "\n",
    "        for year, group in anomaly.groupby('time.year'):\n",
    "            filename = f'{filepath}Anomaly/{var}{filebase}{datatype}_anom_{year}.nc'\n",
    "            group.to_netcdf(filename, encoding=encoding)\n",
    "        \n",
    "        print(f'Complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f965b81a-2cc5-4471-868a-dcbbb94b8074",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### NARR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2334b1-fc30-4c72-a0fb-68c30f0bff06",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "\n",
    "model    = 'NARR'\n",
    "filepath = '../database_files_final/NARR/'\n",
    "filebase = '_NARR_REANALYSIS_'\n",
    "\n",
    "vars = [\n",
    "    'ffwi', 'hdw', 'pbl', 'prate', 'rh', \n",
    "    'sm',   't2',  'tp',  'u10',   'v10', \n",
    "    'vpd',  'wd',  'ws']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd48ccb-d121-41da-9729-489042a8cd89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for var in vars:\n",
    "    for datatype in ['Abs', 'MIN', 'MAX', 'AVG']:\n",
    "        raw_df = xr.open_mfdataset(f'{filepath}{var}{filebase}{datatype}*.nc', decode_times=True, engine='netcdf4').load()\n",
    "      \n",
    "        print(f'Data loaded, applying harmonics to: {var} {datatype}... ')\n",
    "                \n",
    "        period_normal, anomaly, harmonics_parameters = compute_harmonics_xr(raw_df[var], k=k)\n",
    "\n",
    "        period_normal.attrs = raw_df.attrs.copy()\n",
    "        anomaly.attrs       = raw_df.attrs.copy()\n",
    "\n",
    "        period_normal.attrs.update({'File_creation_date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")})\n",
    "        anomaly.attrs.update({'File_creation_date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")})\n",
    "\n",
    "        period_normal.to_netcdf(f'temp/{model}_{var}_{datatype}_periodnorm.nc', encoding=encoding)\n",
    "        anomaly.to_netcdf(f'temp/{model}_{var}_{datatype}_anomaly.nc', encoding=encoding)\n",
    "        harmonics_parameters.to_netcdf(f'../harmonics_parameters/{model}/{var}_{model}_{datatype}_harmonics_parameters.nc')\n",
    "\n",
    "        print('Full temp files written, splitting into yearly files... ')\n",
    "\n",
    "        period_normal = xr.open_dataset(f'temp/{model}_{var}_{datatype}_periodnorm.nc')#, chunks={'time': 100})\n",
    "        anomaly       = xr.open_dataset(f'temp/{model}_{var}_{datatype}_anomaly.nc')#, chunks={'time': 100})\n",
    "\n",
    "        for year, group in period_normal.groupby('time.year'):\n",
    "            filename = f'{filepath}Period_Normal/{var}{filebase}{datatype}_periodnorm_{year}.nc'\n",
    "            group.to_netcdf(filename, encoding=encoding)\n",
    "\n",
    "        for year, group in anomaly.groupby('time.year'):\n",
    "            filename = f'{filepath}Anomaly/{var}{filebase}{datatype}_anom_{year}.nc'\n",
    "            group.to_netcdf(filename, encoding=encoding)\n",
    "        \n",
    "        print(f'Complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4097c9-3cb2-4a5f-89fb-fecd9a07aa99",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### NAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc41db2a-be51-4dbe-8695-0f7d1f847ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "\n",
    "model    = 'NAM'\n",
    "filepath = '../database_files_final/NAM/'\n",
    "filebase = '_NAM_HISTORICAL_'\n",
    "\n",
    "vars = [\n",
    "    'cape', 'ffwi', 'gust', 'hdw',  'prate', \n",
    "    'rh',   'sm',   't2',   'tp',  'u10',  \n",
    "    'v10',  'vpd',  'wd',   'ws']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885beb05-3980-4d05-b97a-8245c9152ae7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for var in vars:\n",
    "    for datatype in ['Abs', 'MIN', 'MAX', 'AVG']:\n",
    "        raw_df = xr.open_mfdataset(f'{filepath}{var}{filebase}{datatype}*.nc', decode_times=True, engine='netcdf4').load()\n",
    "      \n",
    "        print(f'Data loaded, applying harmonics to: {var} {datatype}... ')\n",
    "                \n",
    "        large_data = True if (datatype == 'Abs') else False\n",
    "                \n",
    "        period_normal, anomaly, harmonics_parameters = compute_harmonics_xr(raw_df[var], k=k, large_data=large_data)\n",
    "\n",
    "        period_normal.attrs = raw_df.attrs.copy()\n",
    "        anomaly.attrs       = raw_df.attrs.copy()\n",
    "\n",
    "        period_normal.attrs.update({'File_creation_date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")})\n",
    "        anomaly.attrs.update({'File_creation_date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")})\n",
    "\n",
    "        period_normal.to_netcdf(f'temp/{model}_{var}_{datatype}_periodnorm.nc', encoding=encoding)\n",
    "        anomaly.to_netcdf(f'temp/{model}_{var}_{datatype}_anomaly.nc', encoding=encoding)\n",
    "        harmonics_parameters.to_netcdf(f'../harmonics_parameters/{model}/{var}_{model}_{datatype}_harmonics_parameters.nc')\n",
    "\n",
    "        print('Full temp files written, splitting into yearly files... ')\n",
    "\n",
    "        period_normal = xr.open_dataset(f'temp/{model}_{var}_{datatype}_periodnorm.nc')\n",
    "        anomaly       = xr.open_dataset(f'temp/{model}_{var}_{datatype}_anomaly.nc')\n",
    "\n",
    "        for year, group in period_normal.groupby('time.year'):\n",
    "            filename = f'{filepath}Period_Normal/{var}{filebase}{datatype}_periodnorm_{year}.nc'\n",
    "            group.to_netcdf(filename, encoding=encoding)\n",
    "\n",
    "        for year, group in anomaly.groupby('time.year'):\n",
    "            filename = f'{filepath}Anomaly/{var}{filebase}{datatype}_anom_{year}.nc'\n",
    "            group.to_netcdf(filename, encoding=encoding)\n",
    "        \n",
    "        print(f'Complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a41c6ed-6980-46af-9f0d-e250a3e96a21",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### HRRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de184c51-1636-4d67-8bd6-484c05b47344",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "\n",
    "model    = 'HRRR'\n",
    "filepath = '../database_files_final/HRRR/'\n",
    "filebase = '_HRRR_HISTORICAL_'\n",
    "\n",
    "vars = [\n",
    "    'cape', 'd2',    'ffwi', 'gust', 'hdw', \n",
    "    'pbl',  'prate', 'rh',   'sm',   't2',\n",
    "    'tp',   'u10',   'v10',  'vpd',  'wd', \n",
    "    'ws']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "167f8c5a-5e45-4e03-9942-4d4a7bcb7b3f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s2sfire/miniconda3/envs/noaa_s2s/lib/python3.12/site-packages/xarray/backends/plugins.py:80: RuntimeWarning: Engine 'gini' loading failed:\n",
      "Struct() takes at most 1 argument (3 given)\n",
      "  warnings.warn(f\"Engine {name!r} loading failed:\\n{ex}\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded, applying harmonics to: v10 Abs... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written, splitting into yearly files... \n",
      "Complete!\n",
      "Data loaded, applying harmonics to: v10 MIN... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written, splitting into yearly files... \n",
      "Complete!\n",
      "Data loaded, applying harmonics to: v10 MAX... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written, splitting into yearly files... \n",
      "Complete!\n",
      "Data loaded, applying harmonics to: v10 AVG... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written, splitting into yearly files... \n",
      "Complete!\n",
      "Data loaded, applying harmonics to: vpd Abs... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written, splitting into yearly files... \n",
      "Complete!\n",
      "Data loaded, applying harmonics to: vpd MIN... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written, splitting into yearly files... \n",
      "Complete!\n",
      "Data loaded, applying harmonics to: vpd MAX... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written, splitting into yearly files... \n",
      "Complete!\n",
      "Data loaded, applying harmonics to: vpd AVG... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written, splitting into yearly files... \n",
      "Complete!\n",
      "Data loaded, applying harmonics to: wd Abs... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written, splitting into yearly files... \n",
      "Complete!\n",
      "Data loaded, applying harmonics to: wd MIN... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written, splitting into yearly files... \n",
      "Complete!\n",
      "Data loaded, applying harmonics to: wd MAX... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written, splitting into yearly files... \n",
      "Complete!\n",
      "Data loaded, applying harmonics to: wd AVG... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written, splitting into yearly files... \n",
      "Complete!\n",
      "Data loaded, applying harmonics to: ws Abs... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written, splitting into yearly files... \n",
      "Complete!\n",
      "Data loaded, applying harmonics to: ws MIN... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written, splitting into yearly files... \n",
      "Complete!\n",
      "Data loaded, applying harmonics to: ws MAX... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written, splitting into yearly files... \n",
      "Complete!\n",
      "Data loaded, applying harmonics to: ws AVG... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written, splitting into yearly files... \n",
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "for var in vars:\n",
    "    for datatype in ['Abs', 'MIN', 'MAX', 'AVG']:\n",
    "        raw_df = xr.open_mfdataset(f'{filepath}{var}{filebase}{datatype}*.nc', decode_times=True, engine='netcdf4').load()\n",
    "      \n",
    "        print(f'Data loaded, applying harmonics to: {var} {datatype}... ')\n",
    "                \n",
    "        period_normal, anomaly, harmonics_parameters = compute_harmonics_xr(raw_df[var], k=k, large_data=True)\n",
    "\n",
    "        period_normal.attrs = raw_df.attrs.copy()\n",
    "        anomaly.attrs       = raw_df.attrs.copy()\n",
    "\n",
    "        period_normal.attrs.update({'File_creation_date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")})\n",
    "        anomaly.attrs.update({'File_creation_date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")})\n",
    "\n",
    "        period_normal.to_netcdf(f'temp/{model}_{var}_{datatype}_periodnorm.nc', encoding=encoding)\n",
    "        anomaly.to_netcdf(f'temp/{model}_{var}_{datatype}_anomaly.nc', encoding=encoding)\n",
    "        harmonics_parameters.to_netcdf(f'../harmonics_parameters/{model}/{var}_{model}_{datatype}_harmonics_parameters.nc')\n",
    "\n",
    "        print('Full temp files written, splitting into yearly files... ')\n",
    "\n",
    "        period_normal = xr.open_dataset(f'temp/{model}_{var}_{datatype}_periodnorm.nc')\n",
    "        anomaly       = xr.open_dataset(f'temp/{model}_{var}_{datatype}_anomaly.nc')\n",
    "\n",
    "        for year, group in period_normal.groupby('time.year'):\n",
    "            filename = f'{filepath}Period_Normal/{var}{filebase}{datatype}_periodnorm_{year}.nc'\n",
    "            group.to_netcdf(filename, encoding=encoding)\n",
    "\n",
    "        for year, group in anomaly.groupby('time.year'):\n",
    "            filename = f'{filepath}Anomaly/{var}{filebase}{datatype}_anom_{year}.nc'\n",
    "            group.to_netcdf(filename, encoding=encoding)\n",
    "        \n",
    "        print(f'Complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c749df10-871a-4d00-bda9-879e25013cb2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### CONUS404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "843e86a3-dbbb-406a-820d-ffbc4519bb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "\n",
    "model    = 'CONUS404'\n",
    "filepath = '../database_files_final/CONUS404/'\n",
    "filebase = '_CONUS404_ANALYSIS_'\n",
    "\n",
    "vars = [\n",
    "    'd2',    'ffwi', 'hdw',    'mlcape', 'pbl', \n",
    "    'prate', 'rh',   'sbcape', 't2',     'tp', \n",
    "    'u10',   'v10',  'vpd',    'vsm',    'wd', \n",
    "    'ws']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f64881c7-9c70-4298-9deb-ae5b807550ef",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded, applying harmonics to: wd MIN... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written, splitting into yearly files... \n",
      "Complete!\n",
      "Data loaded, applying harmonics to: wd MAX... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written, splitting into yearly files... \n",
      "Complete!\n",
      "Data loaded, applying harmonics to: wd AVG... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written, splitting into yearly files... \n",
      "Complete!\n",
      "Data loaded, applying harmonics to: ws MIN... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written, splitting into yearly files... \n",
      "Complete!\n",
      "Data loaded, applying harmonics to: ws MAX... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written, splitting into yearly files... \n",
      "Complete!\n",
      "Data loaded, applying harmonics to: ws AVG... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written, splitting into yearly files... \n",
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "for var in vars:\n",
    "    for datatype in ['MIN', 'MAX', 'AVG']:\n",
    "        raw_df = xr.open_mfdataset(f'{filepath}{var}{filebase}{datatype}*.nc', decode_times=True, engine='netcdf4').load()\n",
    "      \n",
    "        print(f'Data loaded, applying harmonics to: {var} {datatype}... ')\n",
    "                \n",
    "        period_normal, anomaly, harmonics_parameters = compute_harmonics_xr(raw_df[var], k=k, large_data=True)\n",
    "\n",
    "        period_normal.attrs = raw_df.attrs.copy()\n",
    "        anomaly.attrs       = raw_df.attrs.copy()\n",
    "\n",
    "        period_normal.attrs.update({'File_creation_date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")})\n",
    "        anomaly.attrs.update({'File_creation_date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")})\n",
    "\n",
    "        period_normal.to_netcdf(f'temp/{model}_{var}_{datatype}_periodnorm.nc', encoding=encoding)\n",
    "        anomaly.to_netcdf(f'temp/{model}_{var}_{datatype}_anomaly.nc', encoding=encoding)\n",
    "        harmonics_parameters.to_netcdf(f'../harmonics_parameters/{model}/{var}_{model}_{datatype}_harmonics_parameters.nc')\n",
    "\n",
    "        print('Full temp files written, splitting into yearly files... ')\n",
    "\n",
    "        period_normal = xr.open_dataset(f'temp/{model}_{var}_{datatype}_periodnorm.nc')#, chunks={'time': 100})\n",
    "        anomaly       = xr.open_dataset(f'temp/{model}_{var}_{datatype}_anomaly.nc')#, chunks={'time': 100})\n",
    "\n",
    "        for year, group in period_normal.groupby('time.year'):\n",
    "            filename = f'{filepath}Period_Normal/{var}{filebase}{datatype}_periodnorm_{year}.nc'\n",
    "            group.to_netcdf(filename, encoding=encoding)\n",
    "\n",
    "        for year, group in anomaly.groupby('time.year'):\n",
    "            filename = f'{filepath}Anomaly/{var}{filebase}{datatype}_anom_{year}.nc'\n",
    "            group.to_netcdf(filename, encoding=encoding)\n",
    "        \n",
    "        print(f'Complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a13476a0-3527-459c-8903-46294a8529a4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s2sfire/miniconda3/envs/noaa_s2s/lib/python3.12/site-packages/xarray/backends/plugins.py:80: RuntimeWarning: Engine 'gini' loading failed:\n",
      "Struct() takes at most 1 argument (3 given)\n",
      "  warnings.warn(f\"Engine {name!r} loading failed:\\n{ex}\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# CONUS404 Abs are too large to process at once; needs to be split into 4\n",
    "for var in vars:\n",
    "    for datatype in ['Abs']:\n",
    "        raw_df = xr.open_mfdataset(f'{filepath}{var}{filebase}{datatype}*.nc', decode_times=True, engine='netcdf4').load()\n",
    "\n",
    "        ny, nx = raw_df.dims['latitude'], raw_df.dims['longitude']\n",
    "        i_split = ny // 2\n",
    "        j_split = nx // 2\n",
    "\n",
    "        q00 = raw_df.isel(latitude=slice(0, i_split),  longitude=slice(0, j_split))\n",
    "        q00.to_netcdf(f'temp/{model}_{var}_{datatype}_q00.nc', encoding=encoding)\n",
    "        del q00\n",
    "        \n",
    "        q01 = raw_df.isel(latitude=slice(0, i_split),  longitude=slice(j_split, nx))\n",
    "        q01.to_netcdf(f'temp/{model}_{var}_{datatype}_q01.nc', encoding=encoding)\n",
    "        del q01\n",
    "        \n",
    "        q10 = raw_df.isel(latitude=slice(i_split, ny), longitude=slice(0, j_split))\n",
    "        q10.to_netcdf(f'temp/{model}_{var}_{datatype}_q10.nc', encoding=encoding)\n",
    "        del q10\n",
    "        \n",
    "        q11 = raw_df.isel(latitude=slice(i_split, ny), longitude=slice(j_split, nx))\n",
    "        q11.to_netcdf(f'temp/{model}_{var}_{datatype}_q11.nc', encoding=encoding)\n",
    "        del q11\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92aa70c1-fd2d-4af3-b819-2ca947982d53",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded, applying harmonics to: CONUS404 d2 Abs q00... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 d2 Abs q01... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 d2 Abs q10... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 d2 Abs q11... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 ffwi Abs q00... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 ffwi Abs q01... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 ffwi Abs q10... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 ffwi Abs q11... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 hdw Abs q00... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 hdw Abs q01... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 hdw Abs q10... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 hdw Abs q11... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 mlcape Abs q00... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 mlcape Abs q01... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 mlcape Abs q10... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 mlcape Abs q11... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 pbl Abs q00... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 pbl Abs q01... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 pbl Abs q10... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 pbl Abs q11... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 prate Abs q00... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 prate Abs q01... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 prate Abs q10... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 prate Abs q11... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 rh Abs q00... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 rh Abs q01... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 rh Abs q10... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 rh Abs q11... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 sbcape Abs q00... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 sbcape Abs q01... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 sbcape Abs q10... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 sbcape Abs q11... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 t2 Abs q00... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 t2 Abs q01... \n",
      "Harmonics coefficients computed: 1,2,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 t2 Abs q10... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 t2 Abs q11... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 tp Abs q00... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 tp Abs q01... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 tp Abs q10... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 tp Abs q11... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 u10 Abs q00... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 u10 Abs q01... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 u10 Abs q10... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 u10 Abs q11... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 v10 Abs q00... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 v10 Abs q01... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 v10 Abs q10... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 v10 Abs q11... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 vpd Abs q00... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 vpd Abs q01... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 vpd Abs q10... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 vpd Abs q11... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 vsm Abs q00... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 vsm Abs q01... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 vsm Abs q10... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 vsm Abs q11... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 wd Abs q00... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 wd Abs q01... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 wd Abs q10... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 wd Abs q11... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 ws Abs q00... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 ws Abs q01... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 ws Abs q10... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n",
      "Data loaded, applying harmonics to: CONUS404 ws Abs q11... \n",
      "Harmonics coefficients computed: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Harmonics added to mean to compute period normal: 1,2,3,4,5,6,7,8,9,10 Completed.\n",
      "Full temp files written.\n"
     ]
    }
   ],
   "source": [
    "for var in vars:\n",
    "    for q in ['00','01','10','11']:\n",
    "        raw_df = xr.load_dataset(f'temp/{model}_{var}_Abs_q{q}.nc', decode_times=True, engine='netcdf4').load()\n",
    "\n",
    "        print(f'Data loaded, applying harmonics to: {model} {var} Abs q{q}... ')\n",
    "                \n",
    "        period_normal, anomaly, harmonics_parameters = compute_harmonics_xr(raw_df[var], k=k, large_data=True)\n",
    "\n",
    "        period_normal.attrs = raw_df.attrs.copy()\n",
    "        anomaly.attrs       = raw_df.attrs.copy()\n",
    "\n",
    "        period_normal.attrs.update({'File_creation_date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")})\n",
    "        anomaly.attrs.update({'File_creation_date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")})\n",
    "\n",
    "        period_normal.to_netcdf(f'temp/{model}_{var}_Abs_q{q}_periodnorm.nc', encoding=encoding)\n",
    "        anomaly.to_netcdf(f'temp/{model}_{var}_Abs_q{q}_anomaly.nc', encoding=encoding)\n",
    "        harmonics_parameters.to_netcdf(f'temp/{var}_{model}_Abs_q{q}_harmonics_parameters.nc')\n",
    "\n",
    "        print('Full temp files written.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74c475c5-50f5-4ca1-b580-901568a66515",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for var in vars:\n",
    "    ds_00 = xr.open_dataset(f'temp/{var}_{model}_Abs_q00_harmonics_parameters.nc')\n",
    "    ds_01 = xr.open_dataset(f'temp/{var}_{model}_Abs_q01_harmonics_parameters.nc')\n",
    "    ds_10 = xr.open_dataset(f'temp/{var}_{model}_Abs_q10_harmonics_parameters.nc')\n",
    "    ds_11 = xr.open_dataset(f'temp/{var}_{model}_Abs_q11_harmonics_parameters.nc')\n",
    "\n",
    "    ds_full = xr.combine_nested([[ds_00, ds_01], [ds_10, ds_11]],\n",
    "                                concat_dim=['latitude', 'longitude'])\n",
    "\n",
    "    ds_full.to_netcdf(f'../harmonics_parameters/{model}/{var}_{model}_Abs_harmonics_parameters.nc')\n",
    "\n",
    "    print(f'CONUS404 {var} harmonics parameters put back together.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d030b6b-6062-431d-99fe-903937a5bd7a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONUS404 d2 period normals put back together and yearly files written.\n",
      "CONUS404 ffwi period normals put back together and yearly files written.\n",
      "CONUS404 hdw period normals put back together and yearly files written.\n",
      "CONUS404 mlcape period normals put back together and yearly files written.\n",
      "CONUS404 pbl period normals put back together and yearly files written.\n",
      "CONUS404 prate period normals put back together and yearly files written.\n",
      "CONUS404 rh period normals put back together and yearly files written.\n",
      "CONUS404 sbcape period normals put back together and yearly files written.\n",
      "CONUS404 t2 period normals put back together and yearly files written.\n",
      "CONUS404 tp period normals put back together and yearly files written.\n",
      "CONUS404 u10 period normals put back together and yearly files written.\n",
      "CONUS404 v10 period normals put back together and yearly files written.\n",
      "CONUS404 vpd period normals put back together and yearly files written.\n",
      "CONUS404 vsm period normals put back together and yearly files written.\n",
      "CONUS404 wd period normals put back together and yearly files written.\n",
      "CONUS404 ws period normals put back together and yearly files written.\n"
     ]
    }
   ],
   "source": [
    "for var in vars:\n",
    "\n",
    "    ds_00 = xr.load_dataset(f'temp/{model}_{var}_Abs_q00_periodnorm.nc')\n",
    "    ds_01 = xr.load_dataset(f'temp/{model}_{var}_Abs_q01_periodnorm.nc')\n",
    "    ds_10 = xr.load_dataset(f'temp/{model}_{var}_Abs_q10_periodnorm.nc')\n",
    "    ds_11 = xr.load_dataset(f'temp/{model}_{var}_Abs_q11_periodnorm.nc')\n",
    "\n",
    "    ds_full = xr.combine_nested([[ds_00, ds_01], [ds_10, ds_11]],\n",
    "                                concat_dim=['latitude', 'longitude'])\n",
    "\n",
    "    del ds_00, ds_01, ds_10, ds_11\n",
    "\n",
    "    for year, group in ds_full.groupby('time.year'):\n",
    "        filename = f'{filepath}Period_Normal/{var}{filebase}Abs_periodnorm_{year}.nc'\n",
    "        group.to_netcdf(filename, encoding=encoding)\n",
    "        \n",
    "    print(f'CONUS404 {var} period normals put back together and yearly files written.')\n",
    "\n",
    "    del ds_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4b876d2-bbe7-444f-aeb6-d67aade365d9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONUS404 d2 anomalies put back together and yearly files written.\n",
      "CONUS404 ffwi anomalies put back together and yearly files written.\n",
      "CONUS404 hdw anomalies put back together and yearly files written.\n",
      "CONUS404 mlcape anomalies put back together and yearly files written.\n",
      "CONUS404 pbl anomalies put back together and yearly files written.\n",
      "CONUS404 prate anomalies put back together and yearly files written.\n",
      "CONUS404 rh anomalies put back together and yearly files written.\n",
      "CONUS404 sbcape anomalies put back together and yearly files written.\n",
      "CONUS404 t2 anomalies put back together and yearly files written.\n",
      "CONUS404 tp anomalies put back together and yearly files written.\n",
      "CONUS404 u10 anomalies put back together and yearly files written.\n",
      "CONUS404 v10 anomalies put back together and yearly files written.\n",
      "CONUS404 vpd anomalies put back together and yearly files written.\n",
      "CONUS404 vsm anomalies put back together and yearly files written.\n",
      "CONUS404 wd anomalies put back together and yearly files written.\n",
      "CONUS404 ws anomalies put back together and yearly files written.\n"
     ]
    }
   ],
   "source": [
    "for var in vars:\n",
    "\n",
    "    ds_00 = xr.load_dataset(f'temp/{model}_{var}_Abs_q00_anomaly.nc')\n",
    "    ds_01 = xr.load_dataset(f'temp/{model}_{var}_Abs_q01_anomaly.nc')\n",
    "    ds_10 = xr.load_dataset(f'temp/{model}_{var}_Abs_q10_anomaly.nc')\n",
    "    ds_11 = xr.load_dataset(f'temp/{model}_{var}_Abs_q11_anomaly.nc')\n",
    "\n",
    "    ds_full = xr.combine_nested([[ds_00, ds_01], [ds_10, ds_11]],\n",
    "                                concat_dim=['latitude', 'longitude'])\n",
    "\n",
    "    del ds_00, ds_01, ds_10, ds_11\n",
    "\n",
    "    for year, group in ds_full.groupby('time.year'):\n",
    "        filename = f'{filepath}Anomaly/{var}{filebase}Abs_anom_{year}.nc'\n",
    "        group.to_netcdf(filename, encoding=encoding)\n",
    "        \n",
    "    print(f'CONUS404 {var} anomalies put back together and yearly files written.')\n",
    "\n",
    "    del ds_full\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c038e33b-53a0-4847-9846-4396e86fc8cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### UFS_S2S Lead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8083fd8-df0a-42a4-aef5-e5c06686b8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "\n",
    "model    = 'UFS_S2S'\n",
    "filepath = '../database_files_final/UFS_S2S/LEAD/'\n",
    "filebase = '_UFS_S2S_FORECAST_'\n",
    "\n",
    "vars = [\n",
    "    'cape', 'ffwi', 'gust', 'hdw', 'prate', \n",
    "    'rh',   't2',   'u10',  'v10', 'vpd', \n",
    "    'vsm',  'wd',   'ws']\n",
    "\n",
    "prototypes = ['5', '6', '7', '8', 'MPM']\n",
    "datatypes  = ['Abs', 'AVG', 'MIN', 'MAX']\n",
    "leadtypes  = ['day', 'week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f8868f-6c0c-48e0-b704-9a80583ada96",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for prototype in prototypes:                      \n",
    "    for leadtype in leadtypes:                       \n",
    "        if leadtype == 'day':                       \n",
    "            leads = [f'{i:02d}' for i in range(36)]  \n",
    "        if leadtype == 'week':                      \n",
    "            leads = [f'{i:02d}' for i in range(6)]                          \n",
    "        for var in vars:                \n",
    "            for lead in leads:\n",
    "                for datatype in datatypes:\n",
    "                    if os.path.isfile(f'{filepath}Period_Normal/{prototype}/{leadtype}/{var}{filebase}{datatype}_lead{lead}_periodnorm.nc'):\n",
    "                        print(f'{model} Prototype {prototype} {var} {leadtype}{lead} {datatype} already written. Skipping...')\n",
    "                        continue\n",
    "                    else:\n",
    "                        raw_df = xr.load_dataset(f'{filepath}{prototype}/{leadtype}/{var}{filebase}{datatype}_lead{lead}.nc', engine='netcdf4')\n",
    "          \n",
    "                        print(f'Data loaded, applying harmonics to: {model} Prototype {prototype} {var} {leadtype}{lead} {datatype}... ')\n",
    "                    \n",
    "                        period_normal, anomaly, harmonics_parameters = compute_harmonics_xr(raw_df[var], k=k)\n",
    "    \n",
    "                        period_normal.attrs = raw_df.attrs.copy()\n",
    "                        anomaly.attrs       = raw_df.attrs.copy()\n",
    "    \n",
    "                        period_normal.attrs.update({'File_creation_date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")})\n",
    "                        anomaly.attrs.update({'File_creation_date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")})\n",
    "    \n",
    "                        period_normal.to_netcdf(f'{filepath}Period_Normal/{prototype}/{leadtype}/{var}{filebase}{datatype}_lead{lead}_periodnorm.nc', encoding=encoding)\n",
    "                        anomaly.to_netcdf(f'{filepath}Anomaly/{prototype}/{leadtype}/{var}{filebase}{datatype}_lead{lead}_anom.nc', encoding=encoding)\n",
    "                        harmonics_parameters.to_netcdf(f'../harmonics_parameters/{model}/LEAD/{prototype}/{leadtype}/{var}_{model}_{datatype}_lead{lead}_harmonics_parameters.nc')\n",
    "                \n",
    "                        print(f'Files written. Complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408747ee-ffe7-44fc-9bd7-862a0d279151",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
